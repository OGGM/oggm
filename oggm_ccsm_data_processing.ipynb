{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oggm \n",
    "from oggm import cfg, workflow, utils\n",
    "from oggm.workflow import execute_entity_task\n",
    "import geopandas as gpd\n",
    "import salem, os, netCDF4, logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-12 15:59:48: oggm.cfg: Parameter file: /home/david/oggm/oggm/params.cfg\n"
     ]
    }
   ],
   "source": [
    "cfg.initialize()\n",
    "cfg.PARAMS['continue_on_error'] = True\n",
    "cfg.PATHS['climate_file'] = \"/home/david/Desktop/CCSM4_midHolocene_data/127ka.nc\"\n",
    "cfg.PARAMS['use_multiprocessing'] = True\n",
    "PI_path = \"/home/david/Desktop/CCSM4_midHolocene_data/pi.nc\"\n",
    "rgi_version = '5'\n",
    "rgi_region = '17'\n",
    "cfg.PATHS['working_dir'] = \"/home/david/OGGM_WORKING_DIRECTORY/\"\n",
    "path = utils.get_rgi_intersects_region_file(rgi_region, version=rgi_version)\n",
    "cfg.set_intersects_db(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-12 15:59:51: oggm.workflow: Multiprocessing: using all available processors (N=12)\n"
     ]
    }
   ],
   "source": [
    "entity = gpd.GeoDataFrame.from_file('/home/david/OGGM/rgi/RGIV5/06_rgi50_Iceland/06_rgi50_Iceland.shp')\n",
    "gdirs = oggm.workflow.init_glacier_regions(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<oggm.GlacierDirectory>\n",
       "  RGI id: RGI50-06.00001\n",
       "  Region: 06: Iceland\n",
       "  Subregion: 06-00: Iceland\n",
       "  Glacier type: Glacier\n",
       "  Terminus type: Land-terminating\n",
       "  Area: 4.903 km2\n",
       "  Lon, Lat: (-23.7852, 64.8174)\n",
       "  Grid (nx, ny): (118, 117)\n",
       "  Grid (dx, dy): (41.0, -41.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdir = gdirs[0]\n",
    "gdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.datetime(1950, 10, 1, 0, 0),\n",
       "       datetime.datetime(1950, 11, 1, 0, 0),\n",
       "       datetime.datetime(1950, 12, 1, 0, 0),\n",
       "       datetime.datetime(1951, 1, 1, 0, 0),\n",
       "       datetime.datetime(1951, 2, 1, 0, 0),\n",
       "       datetime.datetime(1951, 3, 1, 0, 0),\n",
       "       datetime.datetime(1951, 4, 1, 0, 0),\n",
       "       datetime.datetime(1951, 5, 1, 0, 0),\n",
       "       datetime.datetime(1951, 6, 1, 0, 0),\n",
       "       datetime.datetime(1951, 7, 1, 0, 0),\n",
       "       datetime.datetime(1951, 8, 1, 0, 0),\n",
       "       datetime.datetime(1951, 9, 1, 0, 0)], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = gdir.get_filepath('cesm_data')\n",
    "with netCDF4.Dataset(fpath, mode='r') as nc:\n",
    "    time = nc.variables['time']\n",
    "    time = netCDF4.num2date(time[:], time.units)\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.datetime(1901, 10, 1, 0, 0),\n",
       "       datetime.datetime(1901, 11, 1, 0, 0),\n",
       "       datetime.datetime(1901, 12, 1, 0, 0), ...,\n",
       "       datetime.datetime(2015, 7, 1, 0, 0),\n",
       "       datetime.datetime(2015, 8, 1, 0, 0),\n",
       "       datetime.datetime(2015, 9, 1, 0, 0)], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = gdir.get_filepath('climate_monthly')\n",
    "with netCDF4.Dataset(fpath, mode='r') as nc:\n",
    "    time = nc.variables['time']\n",
    "    time = netCDF4.num2date(time[:], time.units)\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put this in the function def (see process_cesm_data)\n",
    "filesuffix=''\n",
    "\n",
    "if not (('climate_file' in cfg.PATHS) and\n",
    "        os.path.exists(cfg.PATHS['climate_file'])):\n",
    "    raise IOError('Custom climate file not found')\n",
    "\n",
    "#open dataset for precp use\n",
    "fpath = cfg.PATHS['climate_file']\n",
    "xr_ccsm = xr.open_dataset(fpath, decode_times=False)\n",
    "#open dataset for tmp use\n",
    "xr_ccsm_ts = xr.open_dataset(fpath)\n",
    "#repeating for pi\n",
    "xr_pi = xr.open_dataset(PI_path, decode_times=False)\n",
    "\n",
    "# selecting location\n",
    "lon = gdir.cenlon\n",
    "lat = gdir.cenlat\n",
    "\n",
    "#Setting the longitude to a 0-360 grid [I think...] \"CESM files are in 0-360\"\n",
    "if lon <= 0:\n",
    "    lon += 360\n",
    "\n",
    "#\"take the closest\"\n",
    "#\"TODO: consider GCM interpolation?\"\n",
    "precp = xr_ccsm.PRECC.sel(lat=lat, lon=lon, method='nearest') + xr_ccsm.PRECL.sel(lat=lat, lon=lon, method='nearest')\n",
    "temp = xr_ccsm_ts.TS.sel(lat=lat, lon=lon, method='nearest')\n",
    "precp_pi = xr_pi.PRECC.sel(lat=lat, lon=lon, method='nearest') + xr_pi.PRECL.sel(lat=lat, lon=lon, method='nearest')\n",
    "temp_pi = xr_pi.TS.sel(lat=lat, lon=lon, method='nearest')\n",
    "\n",
    "#convert temp from K to C\n",
    "temp = temp - 273.15\n",
    "temp_pi = temp_pi - 273.15\n",
    "\n",
    "#Take anomaly for CCSM data (with preindustrial control)\n",
    "for i in range(12):\n",
    "    temp.values[i] = temp.values[i] - temp_pi.values[i]\n",
    "for i in range(12):\n",
    "    precp.values[i] = precp.values[i] - precp_pi.values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from normal years to hydrological years\n",
    "sm = cfg.PARAMS['hydro_month_'+gdir.hemisphere]\n",
    "em = sm - 1 if (sm > 1) else 12\n",
    "y0 = int(pd.to_datetime(str(temp.time.values[0])).strftime('%Y'))\n",
    "y1 = int(pd.to_datetime(str(temp.time.values[-1])).strftime('%Y'))\n",
    "#time string for temp/precip (hydro years)\n",
    "time = pd.period_range('{}-{:02d}'.format(y0, sm),'{}-{:02d}'.format(y1, em), freq='M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point, the ccsm3 input year still needs to be reformatted into the proper order. \n",
    "This is where I've struggled the most, espeically making sure it reformats to the correct hydroyear for the hemisphere. \n",
    "\n",
    "The `time` string represents the proper time order/format, and will be the correct hydroyear b/c of the `cfg.PARAMS['hydro_month_'+gdir.hemisphere]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder single year of equil data & add correct time\n",
    "#calculate place in array to concat from (2 for ccsm data)\n",
    "conc_start = sm-2\n",
    "conc_end = sm-14\n",
    "\n",
    "temp_hydro = xr.concat([temp[conc_start:],temp[:conc_end]],dim=\"time\")\n",
    "precp_hydro = xr.concat([precp[conc_start:],precp[:conc_end]],dim=\"time\")\n",
    "temp_hydro['time'] = time\n",
    "precp_hydro['time'] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp_hydro\n",
    "precp = precp_hydro\n",
    "\n",
    "# Workaround for https://github.com/pydata/xarray/issues/1565\n",
    "temp['month'] = ('time', time.month)\n",
    "precp['month'] = ('time', time.month)\n",
    "temp['year'] = ('time', time.year)\n",
    "temp['year'] = ('time', time.year)\n",
    "ny, r = divmod(len(temp.time), 12)\n",
    "assert r == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert m s-1 to mm mth-1 (for precp)\n",
    "ndays = np.tile(cfg.DAYS_IN_MONTH, y1-y0)\n",
    "precp = precp * ndays * (60 * 60 * 24 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Get CRU to apply the anomaly to\"\n",
    "fpath = gdir.get_filepath('climate_monthly')\n",
    "ds_cru = xr.open_dataset(fpath)\n",
    "\n",
    "#\"Add the climate anomaly to CRU clim\"\n",
    "dscru = ds_cru.sel(time=slice('1961', '1990'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp\n",
    "loc_temp = dscru.temp.groupby('time.month').mean()\n",
    "#Oct-Sept format preserved\n",
    "ts_tmp = temp.groupby(temp.month) + loc_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for prcp\n",
    "loc_pre = dscru.prcp.groupby('time.month').mean()\n",
    "ts_pre = precp.groupby(precp.month) + loc_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dates into save format\n",
    "fpath = cfg.PATHS['climate_file']\n",
    "dsindex = salem.GeoNetcdf(fpath, monthbegin=True)\n",
    "time1 = dsindex.variables['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weird recursive way to getting the dates in the correct format to save \n",
    "#only nessisary for 1 year of data, in order to rearrange the months and \n",
    "#get the correct year.\n",
    "time_array = [datetime(temp.time.year[i], temp.time.month[i],1) for i in range(12)]\n",
    "time_nums = netCDF4.date2num(time_array, time1.units, calendar='noleap')\n",
    "time2 = netCDF4.num2date(time_nums[:], time1.units, calendar='noleap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-12 17:27:01: __main__: RGI50-06.00001\n"
     ]
    }
   ],
   "source": [
    "assert np.all(np.isfinite(ts_pre.values))\n",
    "assert np.all(np.isfinite(ts_tmp.values))\n",
    "\n",
    "#\"back to -180 - 180\"\n",
    "loc_lon = precp.lon if precp.lon <= 180 else precp.lon - 360\n",
    "\n",
    "#write to netcdf\n",
    "gdir.write_monthly_climate_file(time2, ts_pre.values, ts_tmp.values, \n",
    "                                float(dscru.ref_hgt), loc_lon, \n",
    "                                precp.lat.values, \n",
    "                                time_unit=time1.units, \n",
    "                                file_name='cesm_data', \n",
    "                                filesuffix=filesuffix)\n",
    "\n",
    "#dsindex._nc.close()\n",
    "xr_ccsm.close()\n",
    "xr_ccsm_ts.close()\n",
    "xr_pi.close()\n",
    "ds_cru.close()\n",
    "\n",
    "#logger message\n",
    "log.info(\"%s\", gdir.rgi_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
